{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 0\n",
    "\n",
    "This notebook generates dark neutrino events, loads them, and describes the output formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import DarkNews as dn\n",
    "from DarkNews import const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating events\n",
    "\n",
    "Let us start by generating a few dark neutrino events for two cases of interest.\n",
    "\n",
    "We do this in two different ways. \n",
    "\n",
    "First using the GenLauncher class, as well as via the command line functionality. In the second case we will need to import the dataframe or the HEPEVT file from the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dn_gen --mzprime=1.25 --m4=0.140 --neval=1000 --D_or_M=dirac --log=INFO\n",
      "9.866349020787781e-14\n",
      "0.00299792458\n",
      "\n",
      "\n",
      "    #########################################################\n",
      "    #   ______           _        _   _                     #\n",
      "    #   |  _  \\         | |      | \\ | |                    #\n",
      "    #   | | | |__ _ _ __| | __   |  \\| | _____      _____   #\n",
      "    #   | | | / _  | ___| |/ /   | .   |/ _ \\ \\ /\\ / / __|  #\n",
      "    #   | |/ / (_| | |  |   <    | |\\  |  __/\\ V  V /\\__ \\  #\n",
      "    #   |___/ \\__,_|_|  |_|\\_\\   \\_| \\_/\\___| \\_/\\_/ |___/  #\n",
      "    #                                                       #\n",
      "    #########################################################\n",
      "    \n",
      "Theory model used: 3+1 dirac HNL model\n",
      "\n",
      "\n",
      "Generating helicity conserving upscattering events for:\n",
      "\tnu(mu) + C12 -> N4 +  C12 -> nu(mu) + e+ + e- + C12\n",
      "\n",
      "decaying N4 using off-shell mediator.\n",
      "Generating helicity flipping upscattering events for:\n",
      "\tnu(mu) + C12 -> N4 +  C12 -> nu(mu) + e+ + e- + C12\n",
      "\n",
      "decaying N4 using off-shell mediator.\n",
      "Generating helicity conserving upscattering events for:\n",
      "\tnu(mu) + proton_in_C12 -> N4 +  proton_in_C12 -> nu(mu) + e+ + e- + proton_in_C12\n",
      "\n",
      "decaying N4 using off-shell mediator.\n",
      "Generating helicity flipping upscattering events for:\n",
      "\tnu(mu) + proton_in_C12 -> N4 +  proton_in_C12 -> nu(mu) + e+ + e- + proton_in_C12\n",
      "\n",
      "decaying N4 using off-shell mediator.\n",
      "Generating helicity conserving upscattering events for:\n",
      "\tnu(mu) + proton_in_H1 -> N4 +  proton_in_H1 -> nu(mu) + e+ + e- + proton_in_H1\n",
      "\n",
      "decaying N4 using off-shell mediator.\n",
      "Generating helicity flipping upscattering events for:\n",
      "\tnu(mu) + proton_in_H1 -> N4 +  proton_in_H1 -> nu(mu) + e+ + e- + proton_in_H1\n",
      "\n",
      "decaying N4 using off-shell mediator.\n",
      "Outputs saved in data/miniboone_fhc/3plus1/m4_0.14_mzprime_1.25_dirac/\n",
      "\n",
      "\n",
      "dn_gen Umu5=1e-3 UD5=35 --chi=0.0031 --gD=2 --mzprime=1.25 --m4=0.080 --m5=0.140 --neval=1000 --D_or_M=majorana --log=INFO\n",
      "9.866349020787781e-14\n",
      "0.00299792458\n",
      "\n",
      "usage: dn_gen [-h] [--mzprime MZPRIME] [--m4 M4] [--m5 M5] [--m6 M6]\n",
      "              [--D_or_M {dirac,majorana}] [--ue4 UE4] [--ue5 UE5] [--ue6 UE6]\n",
      "              [--umu4 UMU4] [--umu5 UMU5] [--umu6 UMU6] [--utau4 UTAU4]\n",
      "              [--utau5 UTAU5] [--utau6 UTAU6] [--ud4 UD4] [--ud5 UD5]\n",
      "              [--ud6 UD6] [--gD GD] [--alphaD ALPHAD] [--epsilon EPSILON]\n",
      "              [--epsilon2 EPSILON2] [--alpha_epsilon2 ALPHA_EPSILON2]\n",
      "              [--chi CHI]\n",
      "              [--exp {miniboone_fhc,microboone,dune_nd_fhc,dune_nd_rhc,minerva_le_fhc,minerva_me_fhc,minos_le_fhc,minos_me_fhc,nova_le_fhc,nd280_fhc}]\n",
      "              [--nopelastic] [--nocoh] [--noHC] [--noHF]\n",
      "              [--log {ERROR,WARNING,INFO,DEBUG}] [--verbose]\n",
      "              [--logfile LOGFILE] [--neval NEVAL] [--nint NINT]\n",
      "              [--neval_warmup NEVAL_WARMUP] [--nint_warmup NINT_WARMUP]\n",
      "              [--pandas] [--numpy] [--hepevt] [--hepevt_unweigh]\n",
      "              [--hepevt_events HEPEVT_EVENTS] [--summary_plots] [--path PATH]\n",
      "dn_gen: error: unrecognized arguments: Umu5=1e-3 UD5=35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cmd_string = \"dn_gen --mzprime=1.25 --m4=0.140 --neval=1000 --D_or_M=dirac --log=INFO\"\n",
    "const.subprocess_cmd(cmd_string)\n",
    "\n",
    "cmd_string = \"dn_gen Umu5=1e-3 UD5=35 --chi=0.0031 --gD=2 --mzprime=1.25 --m4=0.080 --m5=0.140 --neval=1000 --D_or_M=majorana --log=INFO\"\n",
    "const.subprocess_cmd(cmd_string)\n",
    "\n",
    "### DANIELE's METHOD....\n",
    "# Gen = ....\n",
    "# df_m = Gen.run(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/miniboone/3plus2/m5_0.14_m4_0.08_mzprime_1.25_dirac/pandas_df.pckl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-45539667d493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading the events generated via the command line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# df_d = pd.read_pickle('data/miniboone/3plus1/m4_0.14_mzprime_1.25_dirac/pandas_df.pckl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/miniboone/3plus2/m5_0.14_m4_0.08_mzprime_1.25_dirac/pandas_df.pckl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/miniboone/3plus2/m5_0.14_m4_0.08_mzprime_1.25_dirac/pandas_df.pckl'"
     ]
    }
   ],
   "source": [
    "# loading the events generated via the command line\n",
    "df_d = pd.read_pickle('data/miniboone/3plus1/m4_0.14_mzprime_1.25_dirac/pandas_df.pckl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pandas DataFrame Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "Before inspecting the events inside the pandas dataframe, let us check the metadata in [df.attrs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.attrs.html). We have:\n",
    "\n",
    "---\n",
    "1. **experiment**: this is a class DarkNews.experiment.Detector, which contains all the information about the experiment for which the events are generated. It also contains a list of instances of the NuclearTarget class, which contains information about the different scattering target used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of Detector class: \n",
      " NAME FLUXFILE FLUX_NORM ERANGE NUCLEAR_TARGETS FIDUCIAL_MASS_PER_TARGET NUMBER_OF_TARGETS POTS\n",
      "\n",
      "Attributes of NuclearTarget class: \n",
      " name Z N A atomic_Eb electronic_Eb nuclear_Eb atomic_mass excess_mass nuclear_mass beta_decay_energy mass charge is_hadron is_nucleus is_proton is_neutron is_nucleon is_free_nucleon is_bound_nucleon pdgid tau3 F1_EM F2_EM F1_NC F2_NC F3_NC\n",
      "\n",
      "Example of how to look up nuclear targets:\n",
      "701.14 tonnes of C12\n",
      "116.86 tonnes of H1\n"
     ]
    }
   ],
   "source": [
    "# general description of the detector attribute\n",
    "keys = list(df_d.attrs['experiment'].__dict__.keys())\n",
    "print(f\"Attributes of Detector class: \\n\",*keys)\n",
    "print(f\"\\nAttributes of NuclearTarget class: \\n\",*list(df_d.attrs['experiment'].NUCLEAR_TARGETS[0].__dict__))\n",
    "\n",
    "# how much of each target inside the detector?\n",
    "print(\"\\nExample of how to look up nuclear targets:\")\n",
    "for target, fid_mass in zip(df_d.attrs['experiment'].NUCLEAR_TARGETS, df_d.attrs['experiment'].FIDUCIAL_MASS_PER_TARGET):\n",
    "    print(fr\"{round(fid_mass,2)} tonnes of {target.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "2. **bsm_model**: this attribute contains DarkNews.model.Model, which stores all the new physics parameters used in the generation. This includes both low-level information, such as the couplings, say $g_D$, as well as high-level ones, such as the couplings of the $Z^\\prime$ to electrons, $d_e^V$ and $d_e^A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some low-level parameters:\n",
      " gD epsilon epsilonZ Ue4 Umu4 Utau4 Ue5 Umu5 Utau5 Ue6 Umu6 Utau6 UD4 UD5 UD6 m4 m5 m6 mzprime\n",
      "\n",
      "Some high-level parameters:\n",
      " deV deA duV duA ddV ddA dVproton dAproton dVneutron dAneutron cVproton cAproton cVneutron cAneutron\n"
     ]
    }
   ],
   "source": [
    "print(\"Some low-level parameters:\\n\",*list(df_d.attrs['bsm_model'].__dict__.keys())[:19])\n",
    "print(\"\\nSome high-level parameters:\\n\",*list(df_d.attrs['bsm_model'].__dict__.keys())[-14:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Description of the event structure\n",
    "\n",
    "Now we look at the actual events. The DataFrame is a MultiIndex df. Each event contains the components for all the 4-momenta of the particles involved:\n",
    "\n",
    "$$\\nu _\\text{P_projectile} \\,+\\, \\text{Hadronic target} _\\text{P_target} \\to   N _\\text{P_decay_N_parent} \\,+\\, \\text{Hadronic recoil} _\\text{P_recoil}$$\n",
    "\n",
    "$$N _\\text{P_decay_N_parent} \\to N^\\prime _\\text{P_decay_N_daughter} \\,+\\, \\ell^+ _\\text{P_decay_ell_plus} \\,+\\, \\ell^-_\\text{P_decay_ell_minus}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_projectile        t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "P_decay_N_parent    t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "P_target            t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "P_recoil            t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "P_decay_ell_minus   t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "P_decay_ell_plus    t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "P_decay_N_daughter  t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "decay_displacement  t    float64\n",
       "                    x    float64\n",
       "                    y    float64\n",
       "                    z    float64\n",
       "w_decay_rate_0           float64\n",
       "I_decay_rate_0           float64\n",
       "w_event_rate             float64\n",
       "I_event_rate             float64\n",
       "w_flux_avg_xsec          float64\n",
       "I_flux_avg_xsec          float64\n",
       "target                    object\n",
       "target_pdgid               int64\n",
       "scattering_regime         object\n",
       "helicity                  object\n",
       "underlying_process        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "* w_decay_rate_0           float64 -- weight of the decay rate (sum(w) = Gamma_N)\n",
    "* I_decay_rate_0           float64 -- total rate Gamma_N\n",
    "\n",
    "\n",
    "* w_event_rate             float64 -- weight for the event rate (sum(w) = event rate)\n",
    "* I_event_rate             float64 -- total event rate\n",
    "\n",
    "\n",
    "* w_flux_avg_xsec          float64 -- weight of the flux averaged cross section (sum(w) = int(sigma*flux)* exposure)\n",
    "* I_flux_avg_xsec          float64 -- int(sigma*flux)* exposure\n",
    "\n",
    "\n",
    "* target                    object -- target object -- it will typically be a nucleus\n",
    "* target_pdgid               int64 -- pdgID of the target \n",
    "\n",
    "\n",
    "* scattering_regime         object -- regime can be coherent or p-elastic\n",
    "* helicity                  object -- helicity process, can be flipping or conserving. flipping is suppressed\n",
    "* underlying_process        object -- string of the underlying process, e.g, \"nu(mu) + proton_in_C12 -> N4 +  proton_in_C12 -> nu(mu) + e+ + e- + proton_in_C12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
